{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv1d PE回归 regression analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaFIlactipVmzfKpDfPOuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunyingjian/AI-in-well-logging/blob/master/Conv1d_PE%E5%9B%9E%E5%BD%92_regression_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gVGf35ZpmS_",
        "outputId": "8482bd7a-3522-4215-c6ad-fd047054f089"
      },
      "source": [
        "!git clone https://github.com/sunyingjian/numpy-.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'numpy-'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 406 (delta 0), reused 0 (delta 0), pack-reused 403\u001b[K\n",
            "Receiving objects: 100% (406/406), 202.19 MiB | 33.53 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n",
            "Checking out files: 100% (204/204), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehsy9bo4pzgg",
        "outputId": "a12a4548-9d5d-44ab-b186-d200d1f34707"
      },
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jan 23 09:51:10 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEo-5LvTp5P9"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from tensorflow import keras\r\n",
        "%matplotlib inline\r\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "s-ewohcpp7_e",
        "outputId": "2690480f-fb77-4539-b9d5-36518000f4fc"
      },
      "source": [
        "data = pd.read_csv('/content/numpy-/TCN data.csv')\r\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Formation</th>\n",
              "      <th>Depth</th>\n",
              "      <th>GR</th>\n",
              "      <th>ILD_log10</th>\n",
              "      <th>DeltaPHI</th>\n",
              "      <th>PHIND</th>\n",
              "      <th>NM_M</th>\n",
              "      <th>RELPOS</th>\n",
              "      <th>Facies</th>\n",
              "      <th>Well Name</th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.399818</td>\n",
              "      <td>0.298966</td>\n",
              "      <td>0.458149</td>\n",
              "      <td>0.776042</td>\n",
              "      <td>0.219321</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.557385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.400729</td>\n",
              "      <td>0.302738</td>\n",
              "      <td>0.456157</td>\n",
              "      <td>0.888021</td>\n",
              "      <td>0.231865</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978788</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.494046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.401639</td>\n",
              "      <td>0.306417</td>\n",
              "      <td>0.454165</td>\n",
              "      <td>0.903646</td>\n",
              "      <td>0.241224</td>\n",
              "      <td>0</td>\n",
              "      <td>0.956566</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.430707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.402550</td>\n",
              "      <td>0.339247</td>\n",
              "      <td>0.452173</td>\n",
              "      <td>0.880208</td>\n",
              "      <td>0.242479</td>\n",
              "      <td>0</td>\n",
              "      <td>0.935354</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.418039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.403461</td>\n",
              "      <td>0.285601</td>\n",
              "      <td>0.446860</td>\n",
              "      <td>0.869792</td>\n",
              "      <td>0.246049</td>\n",
              "      <td>0</td>\n",
              "      <td>0.914141</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.405371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3227</th>\n",
              "      <td>3227</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.996357</td>\n",
              "      <td>0.155858</td>\n",
              "      <td>0.646070</td>\n",
              "      <td>0.565833</td>\n",
              "      <td>0.129373</td>\n",
              "      <td>1</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.432860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3228</th>\n",
              "      <td>3228</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.997268</td>\n",
              "      <td>0.145818</td>\n",
              "      <td>0.650055</td>\n",
              "      <td>0.576589</td>\n",
              "      <td>0.144021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.673737</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.398277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3229</th>\n",
              "      <td>3229</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.998179</td>\n",
              "      <td>0.169829</td>\n",
              "      <td>0.657359</td>\n",
              "      <td>0.594401</td>\n",
              "      <td>0.144021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.665657</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.378769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3230</th>\n",
              "      <td>3230</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.999089</td>\n",
              "      <td>0.177978</td>\n",
              "      <td>0.658023</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.138135</td>\n",
              "      <td>1</td>\n",
              "      <td>0.657576</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.373955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3231</th>\n",
              "      <td>3231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171282</td>\n",
              "      <td>0.661343</td>\n",
              "      <td>0.586172</td>\n",
              "      <td>0.118065</td>\n",
              "      <td>1</td>\n",
              "      <td>0.649495</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.392070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3232 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  Formation     Depth  ...  Facies  Well Name        PE\n",
              "0              0   0.076923  0.399818  ...       3          7  0.557385\n",
              "1              1   0.076923  0.400729  ...       3          7  0.494046\n",
              "2              2   0.076923  0.401639  ...       3          7  0.430707\n",
              "3              3   0.076923  0.402550  ...       3          7  0.418039\n",
              "4              4   0.076923  0.403461  ...       3          7  0.405371\n",
              "...          ...        ...       ...  ...     ...        ...       ...\n",
              "3227        3227   0.923077  0.996357  ...       5          0  0.432860\n",
              "3228        3228   0.923077  0.997268  ...       5          0  0.398277\n",
              "3229        3229   0.923077  0.998179  ...       5          0  0.378769\n",
              "3230        3230   0.923077  0.999089  ...       5          0  0.373955\n",
              "3231        3231   0.923077  1.000000  ...       5          0  0.392070\n",
              "\n",
              "[3232 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfZAd1vvp-xI",
        "outputId": "e16c30cd-1c28-4846-aec7-58e6a7ddd689"
      },
      "source": [
        "data['Well Name'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    501\n",
              "7    471\n",
              "3    463\n",
              "2    461\n",
              "6    449\n",
              "4    415\n",
              "0    404\n",
              "5     68\n",
              "Name: Well Name, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNGsFtgzqKOq"
      },
      "source": [
        "# 分割数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piS-Xn8yqA5E"
      },
      "source": [
        "test_data = data.loc[data['Well Name']==1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQJmgj5XqMZf"
      },
      "source": [
        "test_data = test_data.drop(columns=['Unnamed: 0','Well Name'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fANtOj4HqOoW"
      },
      "source": [
        "index=data[data['Well Name'].isin([1])].index[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQoyjD4fqQmZ"
      },
      "source": [
        "training_data = data.drop(index = [i for i in range(1381,1882)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JRw9KKLqSf_"
      },
      "source": [
        "train_data = training_data.drop(columns=['Well Name','Unnamed: 0'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYJy1cfsqUhe"
      },
      "source": [
        "train_data =  train_data.reset_index(drop=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFP1NPUUqWie"
      },
      "source": [
        "test_data = test_data.reset_index(drop=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OvvlqjvGqYq-",
        "outputId": "2b675bb1-5edb-48ba-97dc-9e1c42b53cd7"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Formation</th>\n",
              "      <th>Depth</th>\n",
              "      <th>GR</th>\n",
              "      <th>ILD_log10</th>\n",
              "      <th>DeltaPHI</th>\n",
              "      <th>PHIND</th>\n",
              "      <th>NM_M</th>\n",
              "      <th>RELPOS</th>\n",
              "      <th>Facies</th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.399818</td>\n",
              "      <td>0.298966</td>\n",
              "      <td>0.458149</td>\n",
              "      <td>0.776042</td>\n",
              "      <td>0.219321</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.557385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.400729</td>\n",
              "      <td>0.302738</td>\n",
              "      <td>0.456157</td>\n",
              "      <td>0.888021</td>\n",
              "      <td>0.231865</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978788</td>\n",
              "      <td>3</td>\n",
              "      <td>0.494046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.401639</td>\n",
              "      <td>0.306417</td>\n",
              "      <td>0.454165</td>\n",
              "      <td>0.903646</td>\n",
              "      <td>0.241224</td>\n",
              "      <td>0</td>\n",
              "      <td>0.956566</td>\n",
              "      <td>3</td>\n",
              "      <td>0.430707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.402550</td>\n",
              "      <td>0.339247</td>\n",
              "      <td>0.452173</td>\n",
              "      <td>0.880208</td>\n",
              "      <td>0.242479</td>\n",
              "      <td>0</td>\n",
              "      <td>0.935354</td>\n",
              "      <td>3</td>\n",
              "      <td>0.418039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.403461</td>\n",
              "      <td>0.285601</td>\n",
              "      <td>0.446860</td>\n",
              "      <td>0.869792</td>\n",
              "      <td>0.246049</td>\n",
              "      <td>0</td>\n",
              "      <td>0.914141</td>\n",
              "      <td>3</td>\n",
              "      <td>0.405371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2726</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.996357</td>\n",
              "      <td>0.155858</td>\n",
              "      <td>0.646070</td>\n",
              "      <td>0.565833</td>\n",
              "      <td>0.129373</td>\n",
              "      <td>1</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>5</td>\n",
              "      <td>0.432860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.997268</td>\n",
              "      <td>0.145818</td>\n",
              "      <td>0.650055</td>\n",
              "      <td>0.576589</td>\n",
              "      <td>0.144021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.673737</td>\n",
              "      <td>5</td>\n",
              "      <td>0.398277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2728</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.998179</td>\n",
              "      <td>0.169829</td>\n",
              "      <td>0.657359</td>\n",
              "      <td>0.594401</td>\n",
              "      <td>0.144021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.665657</td>\n",
              "      <td>5</td>\n",
              "      <td>0.378769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2729</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.999089</td>\n",
              "      <td>0.177978</td>\n",
              "      <td>0.658023</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.138135</td>\n",
              "      <td>1</td>\n",
              "      <td>0.657576</td>\n",
              "      <td>5</td>\n",
              "      <td>0.373955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2730</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171282</td>\n",
              "      <td>0.661343</td>\n",
              "      <td>0.586172</td>\n",
              "      <td>0.118065</td>\n",
              "      <td>1</td>\n",
              "      <td>0.649495</td>\n",
              "      <td>5</td>\n",
              "      <td>0.392070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2731 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Formation     Depth        GR  ...    RELPOS  Facies        PE\n",
              "0      0.076923  0.399818  0.298966  ...  1.000000       3  0.557385\n",
              "1      0.076923  0.400729  0.302738  ...  0.978788       3  0.494046\n",
              "2      0.076923  0.401639  0.306417  ...  0.956566       3  0.430707\n",
              "3      0.076923  0.402550  0.339247  ...  0.935354       3  0.418039\n",
              "4      0.076923  0.403461  0.285601  ...  0.914141       3  0.405371\n",
              "...         ...       ...       ...  ...       ...     ...       ...\n",
              "2726   0.923077  0.996357  0.155858  ...  0.681818       5  0.432860\n",
              "2727   0.923077  0.997268  0.145818  ...  0.673737       5  0.398277\n",
              "2728   0.923077  0.998179  0.169829  ...  0.665657       5  0.378769\n",
              "2729   0.923077  0.999089  0.177978  ...  0.657576       5  0.373955\n",
              "2730   0.923077  1.000000  0.171282  ...  0.649495       5  0.392070\n",
              "\n",
              "[2731 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJB60hSdsiCT"
      },
      "source": [
        "#分割数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8VO16eLshl_"
      },
      "source": [
        "training_data = training_data.values"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_7-GyVms409"
      },
      "source": [
        "seq_length = 32\r\n",
        "data_ = []\r\n",
        "for i in range(len(train_data)-seq_length):\r\n",
        "  if training_data[i,-2]!=training_data[i+seq_length,-2]:\r\n",
        "    continue\r\n",
        "  data_.append(train_data.iloc[i:i+seq_length])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFJluhk6s8ti"
      },
      "source": [
        "data_ = np.array([df.values for df in data_])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrfGT_uWtJ2s"
      },
      "source": [
        "X = data_[:,:,:9]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6QmNTi9tNNJ"
      },
      "source": [
        "Y = data_[:,:,-1]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auz_nwfytRWW"
      },
      "source": [
        "data_test = []\r\n",
        "for i in range(len(test_data)-seq_length):\r\n",
        "    data_test.append(test_data.iloc[i:i+seq_length])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc0UqHuutTsF"
      },
      "source": [
        "data_test = np.array([df.values for df in data_test])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aut01wEGtV9b"
      },
      "source": [
        "test_x = data_test[:,:,:9]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyrHmnKDtX91"
      },
      "source": [
        "test_y = data_test[:,:,-1]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJATlEkluncU",
        "outputId": "dbe5465b-370c-4ab8-c3c4-318db0e75d15"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2507, 32, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A5naiHsrB9y"
      },
      "source": [
        "# 建立Conv1D网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uNr2IGHq--I"
      },
      "source": [
        "input = tf.keras.Input(shape=(32,9))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7FHmnKxre1e"
      },
      "source": [
        "x = tf.keras.layers.Conv1D(32,kernel_size=2,padding='same',activation='relu')(input)\r\n",
        "x = tf.keras.layers.Dense(64,activation='relu',kernel_regularizer='l2')(x)\r\n",
        "x = tf.keras.layers.Dense(1)(x)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QaSq9jor5pM"
      },
      "source": [
        "model = tf.keras.Model(inputs = input,outputs = x)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2y5Ia-ot1gb",
        "outputId": "80fe5628-1da1-46f5-f2ef-f258fc464a17"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 9)]           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 32, 32)            608       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32, 64)            2112      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32, 1)             65        \n",
            "=================================================================\n",
            "Total params: 2,785\n",
            "Trainable params: 2,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ77FJmst9Bl"
      },
      "source": [
        "#学习率衰减\r\n",
        "learning_rate=0.01\r\n",
        "\r\n",
        "Lr_change=tf.keras.callbacks.ReduceLROnPlateau('val_mae',patience = 20, factor = 0.5, min_lr=0.0001)\r\n",
        "#保存准确率最好的模型\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "filepath=\"best_weight.h5\"\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True,mode='min')\r\n",
        "Adam=tf.keras.optimizers.Adam(learning_rate=learning_rate)\r\n",
        "model.compile(optimizer=Adam,loss='mse',metrics=['mae'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqpaWRiJuSry",
        "outputId": "9eb32953-4e70-429d-d420-4c3fb8cfa6d0"
      },
      "source": [
        "history=model.fit( X,Y,batch_size=128,\r\n",
        "         epochs=100, \r\n",
        "         callbacks=[Lr_change,checkpoint],\r\n",
        "         validation_data=(test_x,test_y))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 18ms/step - loss: 0.7553 - mae: 0.4717 - val_loss: 0.2099 - val_mae: 0.1517\n",
            "\n",
            "Epoch 00001: val_mae improved from inf to 0.15173, saving model to best_weight.h5\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1878 - mae: 0.1063 - val_loss: 0.1504 - val_mae: 0.0797\n",
            "\n",
            "Epoch 00002: val_mae improved from 0.15173 to 0.07972, saving model to best_weight.h5\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1418 - mae: 0.0679 - val_loss: 0.1201 - val_mae: 0.0682\n",
            "\n",
            "Epoch 00003: val_mae improved from 0.07972 to 0.06824, saving model to best_weight.h5\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.1145 - mae: 0.0621 - val_loss: 0.0973 - val_mae: 0.0561\n",
            "\n",
            "Epoch 00004: val_mae improved from 0.06824 to 0.05610, saving model to best_weight.h5\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0942 - mae: 0.0584 - val_loss: 0.0799 - val_mae: 0.0503\n",
            "\n",
            "Epoch 00005: val_mae improved from 0.05610 to 0.05025, saving model to best_weight.h5\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0781 - mae: 0.0557 - val_loss: 0.0661 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00006: val_mae improved from 0.05025 to 0.04696, saving model to best_weight.h5\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0658 - mae: 0.0565 - val_loss: 0.0551 - val_mae: 0.0422\n",
            "\n",
            "Epoch 00007: val_mae improved from 0.04696 to 0.04216, saving model to best_weight.h5\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0550 - mae: 0.0540 - val_loss: 0.0461 - val_mae: 0.0425\n",
            "\n",
            "Epoch 00008: val_mae did not improve from 0.04216\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0466 - mae: 0.0537 - val_loss: 0.0390 - val_mae: 0.0389\n",
            "\n",
            "Epoch 00009: val_mae improved from 0.04216 to 0.03889, saving model to best_weight.h5\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0396 - mae: 0.0539 - val_loss: 0.0324 - val_mae: 0.0360\n",
            "\n",
            "Epoch 00010: val_mae improved from 0.03889 to 0.03598, saving model to best_weight.h5\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0337 - mae: 0.0526 - val_loss: 0.0273 - val_mae: 0.0358\n",
            "\n",
            "Epoch 00011: val_mae improved from 0.03598 to 0.03581, saving model to best_weight.h5\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0290 - mae: 0.0523 - val_loss: 0.0232 - val_mae: 0.0346\n",
            "\n",
            "Epoch 00012: val_mae improved from 0.03581 to 0.03461, saving model to best_weight.h5\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0252 - mae: 0.0529 - val_loss: 0.0199 - val_mae: 0.0349\n",
            "\n",
            "Epoch 00013: val_mae did not improve from 0.03461\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0218 - mae: 0.0524 - val_loss: 0.0176 - val_mae: 0.0375\n",
            "\n",
            "Epoch 00014: val_mae did not improve from 0.03461\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 0.0538 - val_loss: 0.0149 - val_mae: 0.0350\n",
            "\n",
            "Epoch 00015: val_mae did not improve from 0.03461\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0169 - mae: 0.0528 - val_loss: 0.0126 - val_mae: 0.0333\n",
            "\n",
            "Epoch 00016: val_mae improved from 0.03461 to 0.03331, saving model to best_weight.h5\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0528 - val_loss: 0.0110 - val_mae: 0.0333\n",
            "\n",
            "Epoch 00017: val_mae improved from 0.03331 to 0.03328, saving model to best_weight.h5\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0523 - val_loss: 0.0096 - val_mae: 0.0332\n",
            "\n",
            "Epoch 00018: val_mae improved from 0.03328 to 0.03320, saving model to best_weight.h5\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0525 - val_loss: 0.0085 - val_mae: 0.0328\n",
            "\n",
            "Epoch 00019: val_mae improved from 0.03320 to 0.03277, saving model to best_weight.h5\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0526 - val_loss: 0.0075 - val_mae: 0.0335\n",
            "\n",
            "Epoch 00020: val_mae did not improve from 0.03277\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0534 - val_loss: 0.0070 - val_mae: 0.0342\n",
            "\n",
            "Epoch 00021: val_mae did not improve from 0.03277\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0530 - val_loss: 0.0070 - val_mae: 0.0390\n",
            "\n",
            "Epoch 00022: val_mae did not improve from 0.03277\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0549 - val_loss: 0.0056 - val_mae: 0.0331\n",
            "\n",
            "Epoch 00023: val_mae did not improve from 0.03277\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0520 - val_loss: 0.0050 - val_mae: 0.0326\n",
            "\n",
            "Epoch 00024: val_mae improved from 0.03277 to 0.03260, saving model to best_weight.h5\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0516 - val_loss: 0.0050 - val_mae: 0.0343\n",
            "\n",
            "Epoch 00025: val_mae did not improve from 0.03260\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0519 - val_loss: 0.0042 - val_mae: 0.0323\n",
            "\n",
            "Epoch 00026: val_mae improved from 0.03260 to 0.03226, saving model to best_weight.h5\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0530 - val_loss: 0.0040 - val_mae: 0.0320\n",
            "\n",
            "Epoch 00027: val_mae improved from 0.03226 to 0.03204, saving model to best_weight.h5\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0066 - mae: 0.0510 - val_loss: 0.0038 - val_mae: 0.0343\n",
            "\n",
            "Epoch 00028: val_mae did not improve from 0.03204\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0071 - mae: 0.0543 - val_loss: 0.0036 - val_mae: 0.0321\n",
            "\n",
            "Epoch 00029: val_mae did not improve from 0.03204\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0534 - val_loss: 0.0033 - val_mae: 0.0318\n",
            "\n",
            "Epoch 00030: val_mae improved from 0.03204 to 0.03179, saving model to best_weight.h5\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0517 - val_loss: 0.0040 - val_mae: 0.0369\n",
            "\n",
            "Epoch 00031: val_mae did not improve from 0.03179\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0062 - mae: 0.0528 - val_loss: 0.0034 - val_mae: 0.0328\n",
            "\n",
            "Epoch 00032: val_mae did not improve from 0.03179\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0530 - val_loss: 0.0035 - val_mae: 0.0342\n",
            "\n",
            "Epoch 00033: val_mae did not improve from 0.03179\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0520 - val_loss: 0.0029 - val_mae: 0.0322\n",
            "\n",
            "Epoch 00034: val_mae did not improve from 0.03179\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0525 - val_loss: 0.0029 - val_mae: 0.0316\n",
            "\n",
            "Epoch 00035: val_mae improved from 0.03179 to 0.03158, saving model to best_weight.h5\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0529 - val_loss: 0.0039 - val_mae: 0.0384\n",
            "\n",
            "Epoch 00036: val_mae did not improve from 0.03158\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0537 - val_loss: 0.0032 - val_mae: 0.0346\n",
            "\n",
            "Epoch 00037: val_mae did not improve from 0.03158\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0507 - val_loss: 0.0029 - val_mae: 0.0324\n",
            "\n",
            "Epoch 00038: val_mae did not improve from 0.03158\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0508 - val_loss: 0.0028 - val_mae: 0.0320\n",
            "\n",
            "Epoch 00039: val_mae did not improve from 0.03158\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0508 - val_loss: 0.0030 - val_mae: 0.0340\n",
            "\n",
            "Epoch 00040: val_mae did not improve from 0.03158\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0517 - val_loss: 0.0028 - val_mae: 0.0321\n",
            "\n",
            "Epoch 00041: val_mae did not improve from 0.03158\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0505 - val_loss: 0.0024 - val_mae: 0.0306\n",
            "\n",
            "Epoch 00042: val_mae improved from 0.03158 to 0.03060, saving model to best_weight.h5\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0550 - val_loss: 0.0046 - val_mae: 0.0439\n",
            "\n",
            "Epoch 00043: val_mae did not improve from 0.03060\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0556 - val_loss: 0.0029 - val_mae: 0.0339\n",
            "\n",
            "Epoch 00044: val_mae did not improve from 0.03060\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0540 - val_loss: 0.0063 - val_mae: 0.0557\n",
            "\n",
            "Epoch 00045: val_mae did not improve from 0.03060\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0590 - val_loss: 0.0026 - val_mae: 0.0321\n",
            "\n",
            "Epoch 00046: val_mae did not improve from 0.03060\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - mae: 0.0513 - val_loss: 0.0027 - val_mae: 0.0329\n",
            "\n",
            "Epoch 00047: val_mae did not improve from 0.03060\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0520 - val_loss: 0.0027 - val_mae: 0.0333\n",
            "\n",
            "Epoch 00048: val_mae did not improve from 0.03060\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0504 - val_loss: 0.0026 - val_mae: 0.0323\n",
            "\n",
            "Epoch 00049: val_mae did not improve from 0.03060\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0511 - val_loss: 0.0028 - val_mae: 0.0343\n",
            "\n",
            "Epoch 00050: val_mae did not improve from 0.03060\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0514 - val_loss: 0.0024 - val_mae: 0.0315\n",
            "\n",
            "Epoch 00051: val_mae did not improve from 0.03060\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0523 - val_loss: 0.0029 - val_mae: 0.0343\n",
            "\n",
            "Epoch 00052: val_mae did not improve from 0.03060\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0518 - val_loss: 0.0026 - val_mae: 0.0326\n",
            "\n",
            "Epoch 00053: val_mae did not improve from 0.03060\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0503 - val_loss: 0.0027 - val_mae: 0.0339\n",
            "\n",
            "Epoch 00054: val_mae did not improve from 0.03060\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0504 - val_loss: 0.0025 - val_mae: 0.0317\n",
            "\n",
            "Epoch 00055: val_mae did not improve from 0.03060\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0501 - val_loss: 0.0030 - val_mae: 0.0355\n",
            "\n",
            "Epoch 00056: val_mae did not improve from 0.03060\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0509 - val_loss: 0.0027 - val_mae: 0.0335\n",
            "\n",
            "Epoch 00057: val_mae did not improve from 0.03060\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0501 - val_loss: 0.0026 - val_mae: 0.0333\n",
            "\n",
            "Epoch 00058: val_mae did not improve from 0.03060\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0500 - val_loss: 0.0024 - val_mae: 0.0316\n",
            "\n",
            "Epoch 00059: val_mae did not improve from 0.03060\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0516 - val_loss: 0.0045 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00060: val_mae did not improve from 0.03060\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0549 - val_loss: 0.0035 - val_mae: 0.0397\n",
            "\n",
            "Epoch 00061: val_mae did not improve from 0.03060\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0536 - val_loss: 0.0027 - val_mae: 0.0336\n",
            "\n",
            "Epoch 00062: val_mae did not improve from 0.03060\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0508 - val_loss: 0.0030 - val_mae: 0.0360\n",
            "\n",
            "Epoch 00063: val_mae did not improve from 0.03060\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0501 - val_loss: 0.0028 - val_mae: 0.0346\n",
            "\n",
            "Epoch 00064: val_mae did not improve from 0.03060\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0501 - val_loss: 0.0027 - val_mae: 0.0335\n",
            "\n",
            "Epoch 00065: val_mae did not improve from 0.03060\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0504 - val_loss: 0.0027 - val_mae: 0.0340\n",
            "\n",
            "Epoch 00066: val_mae did not improve from 0.03060\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0500 - val_loss: 0.0024 - val_mae: 0.0320\n",
            "\n",
            "Epoch 00067: val_mae did not improve from 0.03060\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0501 - val_loss: 0.0024 - val_mae: 0.0317\n",
            "\n",
            "Epoch 00068: val_mae did not improve from 0.03060\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0498 - val_loss: 0.0027 - val_mae: 0.0338\n",
            "\n",
            "Epoch 00069: val_mae did not improve from 0.03060\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0499 - val_loss: 0.0025 - val_mae: 0.0324\n",
            "\n",
            "Epoch 00070: val_mae did not improve from 0.03060\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0503 - val_loss: 0.0025 - val_mae: 0.0319\n",
            "\n",
            "Epoch 00071: val_mae did not improve from 0.03060\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0503 - val_loss: 0.0024 - val_mae: 0.0322\n",
            "\n",
            "Epoch 00072: val_mae did not improve from 0.03060\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0500 - val_loss: 0.0027 - val_mae: 0.0331\n",
            "\n",
            "Epoch 00073: val_mae did not improve from 0.03060\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0506 - val_loss: 0.0025 - val_mae: 0.0319\n",
            "\n",
            "Epoch 00074: val_mae did not improve from 0.03060\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0506 - val_loss: 0.0027 - val_mae: 0.0334\n",
            "\n",
            "Epoch 00075: val_mae did not improve from 0.03060\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0504 - val_loss: 0.0026 - val_mae: 0.0331\n",
            "\n",
            "Epoch 00076: val_mae did not improve from 0.03060\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0500 - val_loss: 0.0027 - val_mae: 0.0338\n",
            "\n",
            "Epoch 00077: val_mae did not improve from 0.03060\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0501 - val_loss: 0.0022 - val_mae: 0.0307\n",
            "\n",
            "Epoch 00078: val_mae did not improve from 0.03060\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 0.0026 - val_mae: 0.0329\n",
            "\n",
            "Epoch 00079: val_mae did not improve from 0.03060\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0501 - val_loss: 0.0024 - val_mae: 0.0317\n",
            "\n",
            "Epoch 00080: val_mae did not improve from 0.03060\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0498 - val_loss: 0.0030 - val_mae: 0.0362\n",
            "\n",
            "Epoch 00081: val_mae did not improve from 0.03060\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0498 - val_loss: 0.0024 - val_mae: 0.0317\n",
            "\n",
            "Epoch 00082: val_mae did not improve from 0.03060\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0499 - val_loss: 0.0025 - val_mae: 0.0325\n",
            "\n",
            "Epoch 00083: val_mae did not improve from 0.03060\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0493 - val_loss: 0.0027 - val_mae: 0.0336\n",
            "\n",
            "Epoch 00084: val_mae did not improve from 0.03060\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0498 - val_loss: 0.0025 - val_mae: 0.0327\n",
            "\n",
            "Epoch 00085: val_mae did not improve from 0.03060\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0497 - val_loss: 0.0026 - val_mae: 0.0334\n",
            "\n",
            "Epoch 00086: val_mae did not improve from 0.03060\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0494 - val_loss: 0.0027 - val_mae: 0.0341\n",
            "\n",
            "Epoch 00087: val_mae did not improve from 0.03060\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0494 - val_loss: 0.0028 - val_mae: 0.0347\n",
            "\n",
            "Epoch 00088: val_mae did not improve from 0.03060\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0492 - val_loss: 0.0027 - val_mae: 0.0334\n",
            "\n",
            "Epoch 00089: val_mae did not improve from 0.03060\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0493 - val_loss: 0.0023 - val_mae: 0.0312\n",
            "\n",
            "Epoch 00090: val_mae did not improve from 0.03060\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0498 - val_loss: 0.0025 - val_mae: 0.0326\n",
            "\n",
            "Epoch 00091: val_mae did not improve from 0.03060\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0489 - val_loss: 0.0025 - val_mae: 0.0325\n",
            "\n",
            "Epoch 00092: val_mae did not improve from 0.03060\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0493 - val_loss: 0.0024 - val_mae: 0.0320\n",
            "\n",
            "Epoch 00093: val_mae did not improve from 0.03060\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 0.0025 - val_mae: 0.0327\n",
            "\n",
            "Epoch 00094: val_mae did not improve from 0.03060\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0489 - val_loss: 0.0027 - val_mae: 0.0337\n",
            "\n",
            "Epoch 00095: val_mae did not improve from 0.03060\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0494 - val_loss: 0.0026 - val_mae: 0.0332\n",
            "\n",
            "Epoch 00096: val_mae did not improve from 0.03060\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0501 - val_loss: 0.0024 - val_mae: 0.0319\n",
            "\n",
            "Epoch 00097: val_mae did not improve from 0.03060\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0490 - val_loss: 0.0024 - val_mae: 0.0320\n",
            "\n",
            "Epoch 00098: val_mae did not improve from 0.03060\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0488 - val_loss: 0.0024 - val_mae: 0.0321\n",
            "\n",
            "Epoch 00099: val_mae did not improve from 0.03060\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 0.0030 - val_mae: 0.0365\n",
            "\n",
            "Epoch 00100: val_mae did not improve from 0.03060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTVFQnJMuXH4",
        "outputId": "d0bf3964-b600-43bf-b047-1f5529313fd7"
      },
      "source": [
        "import sklearn\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn import linear_model\r\n",
        "import statsmodels.api as sm\r\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VSYWEtxvhSZ"
      },
      "source": [
        "def help(model,test_x,test_y):\r\n",
        "  y_pred = model.predict(test_x)\r\n",
        "  y_pred1 = y_pred[1,:16,:]\r\n",
        "  y_pred_2 = y_pred[:,15,:]\r\n",
        "  y_pred_3 = y_pred[-1,16:,:]\r\n",
        "  y_pred_true = np.append(y_pred1,y_pred_2)\r\n",
        "  y_pred_true = np.append(y_pred_true,y_pred_3)\r\n",
        "  y_test_1 = test_y[1,:16]\r\n",
        "  y_test_2 = test_y[:,15]\r\n",
        "  y_test_3 = test_y[-1,16:]\r\n",
        "  y_test_true = np.append(y_test_1,y_test_2)\r\n",
        "  y_test_true = np.append(y_test_true,y_test_3)\r\n",
        "  print(f'MAE={metrics.mean_absolute_error(y_test_true,y_pred_true)}')\r\n",
        "  print(f'可决系数R2:{r2_score(y_test_true,y_pred_true)}')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X72L72WKvjFz",
        "outputId": "c32b3031-ef70-4af9-a1e5-4c4dd776c46a"
      },
      "source": [
        "help(model,test_x,test_y)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE=0.03717168405799494\n",
            "可决系数R2:0.6156210700219951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx0T3yTwvlNC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}